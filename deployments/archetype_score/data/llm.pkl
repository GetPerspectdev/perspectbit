_: MBFileStub
contentHash: sha1:2480216d53cecfaf471c353ed1278ebd95aca92f
createdAt: 2023-10-03 15:49:42
metadata:
  fileSize: 1183
  object:
    class: LlamaCpp
    description: LlamaCpp(cache=None, verbose=True, callbacks=<langchain.callbacks.manager.CallbackManager object at 0x2cc0b0e20>, tags=None, metadata=None, client=<llama_cpp.llama.Llama object at 0x2cc0b1150>, model_path='./test_model/mistral-7b-instruct-v0.1.Q4_0.gguf', lora_base=None, lora_path=None, n_ctx=32000, n_parts=-1, seed=8855, f16_kv=True, logits_all=False, vocab_only=False, use_mlock=False, n_threads=1, n_batch=512, n_gpu_layers=100, suffix=None, max_tokens=100, temperature=0.75, top_p=1.0, logprobs=None, echo=False, stop=[], repeat_penalty=1.1, top_k=40, last_n_tokens_size=64, use_mmap=True, rope_freq_scale=1.0, rope_freq_base=10000.0, model_kwargs={}, streaming=True, grammar_path=None, grammar=None)
    module: langchain.llms.llamacpp
    package: langchain==0.0.289
schemaVersion: 1
